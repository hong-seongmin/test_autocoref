#!/usr/bin/env python3
"""
Checkpoint Re-evaluation Script
================================

Combined_experiment ì²´í¬í¬ì¸íŠ¸ë“¤ì„ ìˆ˜ì •ëœ í‰ê°€ ë¡œì§ìœ¼ë¡œ ì¬í‰ê°€

íŠ¹ì§•:
- ë°ì´í„° ëˆ„ìˆ˜ ì œê±° (Wikipedia streaming ì‚¬ìš©, ë‹¤ë¥¸ seed)
- LAMBADA@1, Coref F1, Coref@5 í‰ê°€
- ê²°ê³¼ë¥¼ JSON/CSVë¡œ ì €ì¥
- Before/After ë¹„êµ
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

import torch
from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from coref_automl.tune import (
    build_eval_from_lambada,
    build_coref_eval_set,
    eval_lambada_topk,
    eval_coref_f1,
    eval_coref_recall_topk,
)


def find_checkpoints(base_dir: str) -> List[str]:
    """ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
    base_path = Path(base_dir)
    checkpoints = []

    # checkpoint-* íŒ¨í„´ ì°¾ê¸°
    for ckpt_dir in sorted(base_path.glob("checkpoint-*")):
        if ckpt_dir.is_dir() and (ckpt_dir / "config.json").exists():
            checkpoints.append(str(ckpt_dir))

    return checkpoints


def load_checkpoint_info(checkpoint_path: str) -> Dict[str, Any]:
    """ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ë¡œë“œ"""
    config_path = Path(checkpoint_path) / "config.json"
    trainer_state_path = Path(checkpoint_path) / "trainer_state.json"

    info = {
        "path": checkpoint_path,
        "name": Path(checkpoint_path).name,
    }

    # Config ì½ê¸°
    if config_path.exists():
        with open(config_path, encoding="utf-8") as f:
            config = json.load(f)
        info["seq_len"] = config.get("max_position_embeddings", 512)
        info["model_type"] = config.get("model_type", "unknown")

    # Trainer state ì½ê¸°
    if trainer_state_path.exists():
        with open(trainer_state_path, encoding="utf-8") as f:
            state = json.load(f)
        info["global_step"] = state.get("global_step", 0)
        info["epoch"] = state.get("epoch", 0)

    return info


def evaluate_checkpoint(
    checkpoint_path: str,
    seq_len: int = 512,
    lambada_limit: int = 600,
    coref_limit: int = 1600,
) -> Dict[str, Any]:
    """ë‹¨ì¼ ì²´í¬í¬ì¸íŠ¸ í‰ê°€"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Evaluating: {Path(checkpoint_path).name}")
    print(f"{'='*80}")

    eval_start = time.time()

    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
    print("ğŸ“¥ Loading model and tokenizer...")
    load_start = time.time()

    tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)

    # DeBERTa extended sequence length ì²˜ë¦¬
    is_deberta = "deberta" in checkpoint_path.lower() or seq_len > 512

    if is_deberta and seq_len > 512:
        print(f"   Loading DeBERTa with extended seq_len={seq_len}...")
        model = AutoModelForMaskedLM.from_pretrained(
            checkpoint_path,
            ignore_mismatched_sizes=True
        )

        # rel_embeddings ìˆ˜ë™ ë¡œë“œ
        from safetensors import safe_open
        safetensors_path = Path(checkpoint_path) / "model.safetensors"
        if safetensors_path.exists():
            with safe_open(str(safetensors_path), framework='pt', device='cpu') as f:
                if 'deberta.encoder.rel_embeddings.weight' in f.keys():
                    rel_embed_weight = f.get_tensor('deberta.encoder.rel_embeddings.weight')
                    new_size, embed_dim = rel_embed_weight.shape
                    new_rel = torch.nn.Embedding(new_size, embed_dim)
                    new_rel.weight.data = rel_embed_weight.clone()
                    model.deberta.encoder.rel_embeddings = new_rel.to(model.device)

        model.config.max_position_embeddings = seq_len
    else:
        model = AutoModelForMaskedLM.from_pretrained(checkpoint_path)

    tokenizer.model_max_length = seq_len

    load_elapsed = time.time() - load_start
    print(f"âœ… Model loaded ({load_elapsed:.1f}s)")

    # Fill-mask pipeline
    device = 0 if torch.cuda.is_available() else -1
    fill = pipeline("fill-mask", model=model, tokenizer=tokenizer, device=device)
    mask_token = tokenizer.mask_token or "[MASK]"

    results = {
        "checkpoint": checkpoint_path,
        "seq_len": seq_len,
        "evaluated_at": datetime.now().isoformat(),
    }

    # LAMBADA í‰ê°€
    print(f"\nğŸ“– [1/3] LAMBADA evaluation ({lambada_limit} samples)...")
    print(f"   Building LAMBADA set...")
    lbd_start = time.time()
    eval_lbd = build_eval_from_lambada(limit=lambada_limit, seed=42)
    print(f"   Evaluating with fill-mask pipeline (batch_size=64)...")
    eval_start_time = time.time()
    lbd_t1 = eval_lambada_topk(
        fill,
        eval_lbd,
        mask_token=mask_token,
        k=1,
        batch_size=64,
        seq_len=seq_len,
    )
    lbd_elapsed = time.time() - lbd_start
    print(f"   âœ“ LAMBADA@1 = {lbd_t1:.4f} ({lbd_elapsed:.1f}s total, {time.time()-eval_start_time:.1f}s inference)")
    results["lambada_top1"] = lbd_t1
    results["lambada_time"] = lbd_elapsed

    # Coref í‰ê°€ ì„¸íŠ¸ êµ¬ì¶• (ë°ì´í„° ëˆ„ìˆ˜ ì œê±°)
    print(f"\nğŸ”— [2/3] Building coref evaluation set ({coref_limit} samples)...")
    print("   Using streaming Wikipedia (seed=999, different from training) + KLUE validation")
    print("   This may take a few minutes...")
    coref_build_start = time.time()
    eval_coref = build_coref_eval_set(
        limit=coref_limit,
        seed=999,  # í›ˆë ¨ seedì™€ ë‹¤ë¦„ (123 â†’ 999)
        max_seq_len=seq_len
    )
    coref_build_elapsed = time.time() - coref_build_start
    print(f"   âœ“ Coref set built: {len(eval_coref)} samples ({coref_build_elapsed:.1f}s)")
    results["coref_samples"] = len(eval_coref)

    # Coref F1
    print(f"\nğŸ”— [3/3] Evaluating coref metrics...")
    print(f"   Computing Coref F1 on {len(eval_coref)} samples...")
    print(f"   (This involves predicting top-5 nouns for each masked pronoun)")
    coref_f1_start = time.time()
    c_f1 = eval_coref_f1(
        fill,
        eval_coref,
        mask_token=mask_token,
        k=5,
        batch_size=64,
        seq_len=seq_len,
    )
    coref_f1_elapsed = time.time() - coref_f1_start
    samples_per_sec = len(eval_coref) / coref_f1_elapsed
    print(f"   âœ“ Coref F1 = {c_f1:.4f} ({coref_f1_elapsed:.1f}s, {samples_per_sec:.1f} samples/s)")
    results["coref_f1"] = c_f1
    results["coref_f1_time"] = coref_f1_elapsed

    # Coref@5
    print(f"   Computing Coref@5 on {len(eval_coref)} samples...")
    coref_t5_start = time.time()
    c_t5 = eval_coref_recall_topk(
        fill,
        eval_coref,
        mask_token=mask_token,
        k=5,
        batch_size=64,
        seq_len=seq_len,
    )
    coref_t5_elapsed = time.time() - coref_t5_start
    samples_per_sec = len(eval_coref) / coref_t5_elapsed
    print(f"   âœ“ Coref@5 = {c_t5:.4f} ({coref_t5_elapsed:.1f}s, {samples_per_sec:.1f} samples/s)")
    results["coref_top5"] = c_t5
    results["coref_top5_time"] = coref_t5_elapsed

    eval_elapsed = time.time() - eval_start
    results["total_time"] = eval_elapsed

    # ì¢…í•© ì ìˆ˜ (Combined_experimentì™€ ë™ì¼í•œ ê°€ì¤‘ì¹˜)
    score = 0.4 * c_f1 + 0.3 * c_t5 + 0.3 * lbd_t1
    results["score"] = score

    print(f"\nâœ… Evaluation complete!")
    print(f"   Total time: {eval_elapsed:.1f}s")
    print(f"   Score: {score:.4f}")

    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del model
    del fill
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    return results


def load_original_results(checkpoint_path: str) -> Optional[Dict[str, float]]:
    """ì›ë³¸ í‰ê°€ ê²°ê³¼ ë¡œë“œ (ìˆë‹¤ë©´)"""
    # eval_2048.log, eval_1536.log íŒŒì¼ì—ì„œ ê²°ê³¼ ì°¾ê¸°
    base_dir = Path(checkpoint_path).parent
    checkpoint_name = Path(checkpoint_path).name

    for log_file in base_dir.glob("eval_*.log"):
        try:
            with open(log_file, encoding="utf-8") as f:
                content = f.read()

            # í•´ë‹¹ ì²´í¬í¬ì¸íŠ¸ì˜ ê²°ê³¼ ì°¾ê¸°
            if checkpoint_name in content:
                lines = content.split('\n')
                for line in lines:
                    if checkpoint_name in line:
                        # ì˜ˆ: "[1/5] Evaluating checkpoint-410... LAMBADA@1=0.3217 | Coref F1=0.0387 | Coref@5=0.7137"
                        import re
                        match = re.search(
                            r'LAMBADA@1=([\d.]+).*Coref F1=([\d.]+).*Coref@5=([\d.]+)',
                            line
                        )
                        if match:
                            return {
                                "lambada_top1": float(match.group(1)),
                                "coref_f1": float(match.group(2)),
                                "coref_top5": float(match.group(3)),
                            }
        except Exception:
            continue

    return None


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Re-evaluate checkpoints")
    parser.add_argument(
        "--checkpoint-dir",
        default="/home/work/hongseongmin/corefer/runs/combined_experiment",
        help="Base directory containing checkpoints"
    )
    parser.add_argument(
        "--checkpoint",
        help="Specific checkpoint to evaluate (optional)"
    )
    parser.add_argument(
        "--output",
        default="./reevaluation_results.json",
        help="Output file for results"
    )
    parser.add_argument(
        "--lambada-limit",
        type=int,
        default=600,
        help="Number of LAMBADA samples"
    )
    parser.add_argument(
        "--coref-limit",
        type=int,
        default=1600,
        help="Number of Coref samples"
    )

    args = parser.parse_args()

    print("\n" + "="*80)
    print("ğŸ”„ Checkpoint Re-evaluation")
    print("="*80)
    print(f"Checkpoint directory: {args.checkpoint_dir}")
    print(f"Output: {args.output}")
    print("="*80 + "\n")

    overall_start = time.time()

    # ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
    if args.checkpoint:
        checkpoints = [args.checkpoint]
    else:
        checkpoints = find_checkpoints(args.checkpoint_dir)

    if not checkpoints:
        print("âŒ No checkpoints found!")
        return

    print(f"âœ“ Found {len(checkpoints)} checkpoint(s):\n")
    for ckpt in checkpoints:
        info = load_checkpoint_info(ckpt)
        print(f"   - {info['name']}: seq_len={info.get('seq_len', 'unknown')}, "
              f"step={info.get('global_step', 'unknown')}")
    print()

    # í‰ê°€ ì‹¤í–‰
    all_results = []

    # í‰ê°€ ì‹œê°„ ì¶”ì 
    checkpoint_times = []

    for i, ckpt in enumerate(checkpoints, 1):
        print(f"\n{'#'*80}")
        print(f"# [{i}/{len(checkpoints)}] Processing checkpoint")

        # ì§„í–‰ë¥  ë° ETA ê³„ì‚°
        progress_pct = (i - 1) / len(checkpoints) * 100
        if checkpoint_times:
            avg_time = sum(checkpoint_times) / len(checkpoint_times)
            remaining = len(checkpoints) - i + 1
            eta_minutes = (avg_time * remaining) / 60
            print(f"# Progress: {progress_pct:.1f}% | Estimated remaining: {eta_minutes:.1f} min")
        else:
            print(f"# Progress: {progress_pct:.1f}% | Estimating...")

        print(f"{'#'*80}\n")

        info = load_checkpoint_info(ckpt)
        seq_len = info.get("seq_len", 512)

        # ì¬í‰ê°€ (ì‹œê°„ ì¸¡ì •)
        ckpt_start = time.time()
        results = evaluate_checkpoint(
            ckpt,
            seq_len=seq_len,
            lambada_limit=args.lambada_limit,
            coref_limit=args.coref_limit,
        )
        ckpt_elapsed = time.time() - ckpt_start
        checkpoint_times.append(ckpt_elapsed)

        # ì›ë³¸ ê²°ê³¼ ë¡œë“œ (ë¹„êµìš©)
        original = load_original_results(ckpt)
        if original:
            results["original"] = original

            # ì°¨ì´ ê³„ì‚°
            print(f"\nğŸ“Š Comparison (Original â†’ New):")
            print(f"   LAMBADA@1: {original['lambada_top1']:.4f} â†’ {results['lambada_top1']:.4f} "
                  f"({results['lambada_top1'] - original['lambada_top1']:+.4f})")
            print(f"   Coref F1:  {original['coref_f1']:.4f} â†’ {results['coref_f1']:.4f} "
                  f"({results['coref_f1'] - original['coref_f1']:+.4f})")
            print(f"   Coref@5:   {original['coref_top5']:.4f} â†’ {results['coref_top5']:.4f} "
                  f"({results['coref_top5'] - original['coref_top5']:+.4f})")

        # ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ì¶”ê°€
        results["checkpoint_info"] = info
        all_results.append(results)

        # ì¤‘ê°„ ì €ì¥ (ë§¤ ì²´í¬í¬ì¸íŠ¸ë§ˆë‹¤)
        partial_output = Path(args.output).parent / "reevaluation_results_partial.json"

        # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì½ì–´ì„œ ë³‘í•©
        existing_results = []
        if partial_output.exists():
            try:
                with open(partial_output, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì—¬ëŸ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ìŒ“ì¸ ê²½ìš°)
                    if isinstance(existing_data, list):
                        for entry in existing_data:
                            if isinstance(entry, dict) and "results" in entry:
                                existing_results.extend(entry["results"])
                    # ë‹¨ì¼ dictì¸ ê²½ìš°
                    elif isinstance(existing_data, dict) and "results" in existing_data:
                        existing_results = existing_data["results"]
            except Exception as e:
                print(f"   âš ï¸  Warning: Could not read existing partial results: {e}")

        # ì¤‘ë³µ ì œê±° (ê°™ì€ checkpointëŠ” ìµœì‹  ê²°ê³¼ë§Œ ìœ ì§€)
        checkpoint_paths = {res["checkpoint"] for res in all_results}
        filtered_existing = [res for res in existing_results if res["checkpoint"] not in checkpoint_paths]

        # ë³‘í•©ëœ ê²°ê³¼
        merged_results = filtered_existing + all_results

        partial_summary = {
            "evaluated_at": datetime.now().isoformat(),
            "status": "in_progress",
            "completed_checkpoints": i,
            "total_checkpoints": len(checkpoints),
            "progress_pct": (i / len(checkpoints)) * 100,
            "elapsed_time_minutes": (time.time() - overall_start) / 60,
            "lambada_limit": args.lambada_limit,
            "coref_limit": args.coref_limit,
            "total_evaluated": len(merged_results),
            "results": merged_results,
        }
        with open(partial_output, 'w', encoding='utf-8') as f:
            json.dump(partial_summary, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ’¾ Partial results saved to: {partial_output} (total: {len(merged_results)} checkpoints)")

        # ì¤‘ê°„ ìš”ì•½ ì¶œë ¥
        print(f"\n{'â”€'*80}")
        print(f"ğŸ“ˆ Current Progress: {i}/{len(checkpoints)} checkpoints completed")
        print(f"{'â”€'*80}")
        print(f"{'Checkpoint':<20} {'LAMBADA@1':>12} {'Coref F1':>12} {'Coref@5':>12} {'Score':>10}")
        print(f"{'â”€'*80}")
        for res in all_results:
            name = res["checkpoint_info"]["name"]
            print(f"{name:<20} {res['lambada_top1']:>12.4f} {res['coref_f1']:>12.4f} "
                  f"{res['coref_top5']:>12.4f} {res['score']:>10.4f}")
        print(f"{'â”€'*80}\n")

    overall_elapsed = time.time() - overall_start

    # ê²°ê³¼ ì €ì¥
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    summary = {
        "evaluated_at": datetime.now().isoformat(),
        "total_checkpoints": len(checkpoints),
        "total_time_minutes": overall_elapsed / 60,
        "lambada_limit": args.lambada_limit,
        "coref_limit": args.coref_limit,
        "results": all_results,
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print(f"\n{'='*80}")
    print("âœ… Re-evaluation Complete!")
    print(f"{'='*80}")
    print(f"Total time: {overall_elapsed/60:.1f} minutes")
    print(f"Results saved to: {output_path}")
    print(f"{'='*80}\n")

    # ìš”ì•½ í…Œì´ë¸” ì¶œë ¥
    print("Summary Table:")
    print("-" * 80)
    print(f"{'Checkpoint':<20} {'LAMBADA@1':>12} {'Coref F1':>12} {'Coref@5':>12} {'Score':>10}")
    print("-" * 80)
    for res in all_results:
        name = res["checkpoint_info"]["name"]
        print(f"{name:<20} {res['lambada_top1']:>12.4f} {res['coref_f1']:>12.4f} "
              f"{res['coref_top5']:>12.4f} {res['score']:>10.4f}")
    print("-" * 80)

    # CSV ì €ì¥
    csv_path = output_path.with_suffix('.csv')
    with open(csv_path, 'w', encoding='utf-8') as f:
        f.write("checkpoint,seq_len,global_step,lambada_top1,coref_f1,coref_top5,score\n")
        for res in all_results:
            info = res["checkpoint_info"]
            f.write(f"{info['name']},{info.get('seq_len', 'unknown')},{info.get('global_step', 'unknown')},"
                    f"{res['lambada_top1']:.4f},{res['coref_f1']:.4f},{res['coref_top5']:.4f},{res['score']:.4f}\n")

    print(f"\nâœ“ CSV saved to: {csv_path}\n")


if __name__ == "__main__":
    main()
