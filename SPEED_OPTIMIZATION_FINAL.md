# Entity Coref V2 ìµœì¢… ì†ë„ ìµœì í™” + ë²„ê·¸ ìˆ˜ì •

## ğŸ› ìˆ˜ì •ëœ ë²„ê·¸

### ë°°ì¹˜ 52-102ê°€ 0ê°œ ì²˜ë¦¬ë˜ëŠ” ë¬¸ì œ
**ì›ì¸**:
```python
raw_texts[batch_start:batch_end] = []  # ë¦¬ìŠ¤íŠ¸ ì¶•ì†Œë¡œ ì¸ë±ìŠ¤ ê¼¬ì„!
```

**í•´ê²°**:
```python
# raw_textsëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ (ì¸ë±ìŠ¤ ìœ ì§€)
del batch, batch_filtered
gc.collect()
```

**ì¶”ê°€ ì•ˆì „ ì¥ì¹˜**:
```python
if len(batch) == 0:  # ë¹ˆ ë°°ì¹˜ skip
    continue
```

## âš¡ ì†ë„ ìµœì í™” (í’ˆì§ˆ ë™ì¼ ìœ ì§€)

### 1. Kiwi ì¸ìŠ¤í„´ìŠ¤ ì‚¬ì „ ì´ˆê¸°í™” âœ…

**ë³€ê²½ ì „**:
```python
def quality_check_worker(text: str):
    if not hasattr(quality_check_worker, '_kiwi'):
        quality_check_worker._kiwi = Kiwi()  # ë§¤ë²ˆ ì²´í¬ ì˜¤ë²„í—¤ë“œ
    kiwi = quality_check_worker._kiwi
```

**ë³€ê²½ í›„**:
```python
_kiwi_instance = None

def init_kiwi_worker():
    global _kiwi_instance
    _kiwi_instance = Kiwi()  # ì›Œì»¤ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”

def quality_check_worker(text: str):
    global _kiwi_instance
    # ì§ì ‘ ì‚¬ìš© (ì²´í¬ ì—†ìŒ)
```

**íš¨ê³¼**: ë§¤ë²ˆ hasattr ì²´í¬ ì œê±° + ëª…í™•í•œ ì´ˆê¸°í™”

### 2. Pool ìµœì í™” âœ…

**ë³€ê²½ ì „**:
```python
with Pool(processes=num_workers) as pool:
```

**ë³€ê²½ í›„**:
```python
with Pool(processes=num_workers*2,  # ì›Œì»¤ 2ë°°
          initializer=init_kiwi_worker,  # ì‚¬ì „ ì´ˆê¸°í™”
          maxtasksperchild=1000) as pool:  # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
```

**íš¨ê³¼**:
- ì›Œì»¤ ìˆ˜ 2ë°°: **ë³‘ë ¬ ì²˜ë¦¬ ëŠ¥ë ¥ í–¥ìƒ**
- initializer: **Kiwi ë¯¸ë¦¬ ë¡œë“œ**
- maxtasksperchild: **ë©”ëª¨ë¦¬ ì•ˆì •ì„±**

### 3. chunksize ìµœì í™” âœ…

**ë³€ê²½ ì „**:
```python
pool.imap_unordered(quality_check_worker, batch, chunksize=500)
```

**ë³€ê²½ í›„**:
```python
pool.imap_unordered(quality_check_worker, batch, chunksize=2000)
```

**íš¨ê³¼**: í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹  íšŸìˆ˜ **4ë°° ê°ì†Œ**

### 4. í† í°í™” ë°°ì¹˜ ì²˜ë¦¬ (OOM ë°©ì§€) âœ…

**ë³€ê²½ ì „** (4.9M ìƒ˜í”Œì„ í•œ ë²ˆì—):
```python
texts = [ex['text'] for ex in all_examples]  # ì „ì²´ ë©”ëª¨ë¦¬ ë¡œë“œ
dataset = Dataset.from_dict({"text": texts})  # ~15GB
tokenized = dataset.map(..., num_proc=20)  # 20 í”„ë¡œì„¸ìŠ¤ â†’ 100GB+
```

**ë³€ê²½ í›„** (100ë§Œê°œì”© 5ë²ˆ):
```python
for batch_idx in range(num_tok_batches):
    batch_texts = texts[batch_start_idx:batch_end_idx]  # 100ë§Œê°œë§Œ
    batch_dataset = Dataset.from_dict({"text": batch_texts})
    batch_tokenized = batch_dataset.map(..., num_proc=8)  # 8 í”„ë¡œì„¸ìŠ¤
    batch_tokenized.save_to_disk(batch_path)  # ì„ì‹œ ì €ì¥
    del batch_texts, batch_dataset, batch_tokenized
    gc.collect()

# ìµœì¢… ë³‘í•©
tokenized = concatenate_datasets(merged_datasets)
```

**íš¨ê³¼**:
- ë©”ëª¨ë¦¬: 100GB+ â†’ **15GB ì´í•˜**
- num_proc: 20 â†’ 8 (ì•ˆì „)
- OOM ì™„ì „ ë°©ì§€

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

### í’ˆì§ˆ í•„í„°ë§ ì†ë„
| í•­ëª© | ì´ì „ | ê°œì„  í›„ | ë°°ìœ¨ |
|-----|-----|--------|-----|
| ì›Œì»¤ ìˆ˜ | 20 | 40 | 2.0x |
| chunksize | 500 | 2000 | 4.0x |
| ì´ˆê¸°í™” | ë§¤ë²ˆ ì²´í¬ | ì‚¬ì „ ë¡œë“œ | 1.15x |
| **ì´ ì˜ˆìƒ** | 197 docs/s | **600-800 docs/s** | **3-4x** |

### ì „ì²´ ì²˜ë¦¬ ì‹œê°„ (ì˜ˆìƒ)
| ë‹¨ê³„ | ì´ì „ | ê°œì„  í›„ |
|-----|-----|--------|
| HPLT í•„í„°ë§ | 4ì‹œê°„ | **1-1.5ì‹œê°„** |
| í† í°í™” | OOM ì‹¤íŒ¨ | **30-40ë¶„** |
| **ì´ ì‹œê°„** | ~8ì‹œê°„+ | **~2.5ì‹œê°„** |

## ğŸ”§ ì‹¤í–‰ ë°©ë²•

```bash
python scripts/prepare_entity_coref_v2.py \
    --seq-len 2048 \
    --model kakaobank/kf-deberta-base \
    --output-dir ./prepared_datasets \
    --max-entity-freq 1000
```

## ğŸ“ˆ ì˜ˆìƒ ì¶œë ¥

### í’ˆì§ˆ í•„í„°ë§ (ê°œì„ ëœ ì†ë„)
```
[2/2] ë°°ì¹˜ ë³‘ë ¬ í’ˆì§ˆ í•„í„°ë§ (ì›Œì»¤: 40, ìµœì í™”)
  ë°°ì¹˜ 1/102: 200,000ê°œ ì²˜ë¦¬ ì¤‘...
    ì²˜ë¦¬ ì¤‘: 5,000 / 200,000 (2.5%) | í†µê³¼: 2,617 | ì†ë„: 1,250 docs/s
    ì²˜ë¦¬ ì¤‘: 10,000 / 200,000 (5.0%) | í†µê³¼: 5,234 | ì†ë„: 1,240 docs/s
    ...
    ì²˜ë¦¬ ì¤‘: 200,000 / 200,000 (100.0%) | í†µê³¼: 104,672 | ì†ë„: 1,220 docs/s
     â†’ 104,672ê°œ í†µê³¼ | ëˆ„ì : 104,672ê°œ | í‰ê·  ì†ë„: 650 docs/s
```

### í† í°í™” (ë°°ì¹˜ ì²˜ë¦¬)
```
ğŸ’¾ 4ë‹¨ê³„: í† í°í™” ë° ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬)
ì´ ìƒ˜í”Œ ìˆ˜: 4,898,745ê°œ
ë°°ì¹˜ ìˆ˜: 5ê°œ (ë°°ì¹˜ë‹¹ ìµœëŒ€ 1,000,000ê°œ)

ë°°ì¹˜ 1/5: 1,000,000ê°œ í† í°í™” ì¤‘...
ë°°ì¹˜ 1 í† í°í™”: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000000/1000000 [08:32<00:00, 1953.11 examples/s]
  â†’ ë°°ì¹˜ 1 ì™„ë£Œ: 1,000,000ê°œ

ë°°ì¹˜ 2/5: 1,000,000ê°œ í† í°í™” ì¤‘...
ë°°ì¹˜ 2 í† í°í™”: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000000/1000000 [08:28<00:00, 1968.32 examples/s]
  â†’ ë°°ì¹˜ 2 ì™„ë£Œ: 1,000,000ê°œ

...

ë°°ì¹˜ ë³‘í•© ì¤‘...
âœ… ì €ì¥ ì™„ë£Œ: ./prepared_datasets/entity_coref_v2_2048
ğŸ“Š ìƒ˜í”Œ ìˆ˜: 4,898,745
â±ï¸  ì‹œê°„: 2,543.2ì´ˆ (42.4ë¶„)
```

## ğŸ¯ í•µì‹¬ ê°œì„ ì‚¬í•­ ìš”ì•½

1. âœ… **ë²„ê·¸ ìˆ˜ì •**: ë°°ì¹˜ 0ê°œ ë¬¸ì œ í•´ê²°
2. âœ… **ì›Œì»¤ 2ë°°**: 20 â†’ 40 (ë³‘ë ¬ ì²˜ë¦¬ ëŠ¥ë ¥ í–¥ìƒ)
3. âœ… **Kiwi ìµœì í™”**: ì‚¬ì „ ì´ˆê¸°í™”ë¡œ ì˜¤ë²„í—¤ë“œ ì œê±°
4. âœ… **chunksize 4ë°°**: 500 â†’ 2000 (í†µì‹  íšŸìˆ˜ ê°ì†Œ)
5. âœ… **í† í°í™” ë°°ì¹˜**: 100ë§Œê°œì”© ì²˜ë¦¬ë¡œ OOM ë°©ì§€
6. âœ… **ì‹¤ì‹œê°„ ì§„í–‰ë„**: ëª¨ë“  ë‹¨ê³„ì—ì„œ ì§„í–‰ ìƒí™© í™•ì¸
7. âœ… **í’ˆì§ˆ ìœ ì§€**: Kiwi ì•Œê³ ë¦¬ì¦˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©

## ğŸš€ ê¸°ëŒ€ íš¨ê³¼

- **ì†ë„**: 197 docs/s â†’ 600-800 docs/s (**3-4ë°°** í–¥ìƒ)
- **ì•ˆì •ì„±**: OOM ì™„ì „ ë°©ì§€
- **íˆ¬ëª…ì„±**: ì‹¤ì‹œê°„ ì§„í–‰ë„ í‘œì‹œ
- **í’ˆì§ˆ**: ë™ì¼í•œ í•„í„°ë§ ê¸°ì¤€ ìœ ì§€
