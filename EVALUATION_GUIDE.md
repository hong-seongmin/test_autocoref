# MLM v2 Checkpoint Evaluation Guide

μ΄ λ¬Έμ„λ” MLM v2λ΅ ν›λ ¨λ μ²΄ν¬ν¬μΈνΈλ“¤μ„ Real@1, Real@5, LAMBADA@1 λ©”νΈλ¦­μΌλ΅ ν‰κ°€ν•λ” λ°©λ²•μ„ μ„¤λ…ν•©λ‹λ‹¤.

## ν‰κ°€ λ©”νΈλ¦­ μ„¤λ…

### Real@1 (Entity Coreference Top-1 Accuracy)
- **λ©μ **: κ°μ²΄ μƒνΈμ°Έμ΅° ν•΄κ²°μ top-1 μ •ν™•λ„ μΈ΅μ •
- **λ°©λ²•**:
  - Wikipediaμ™€ KLUE λ°μ΄ν„°μ—μ„ κ°™μ€ λ…μ‚¬κ°€ 2λ² μ΄μƒ λ‚μ¤λ” ν…μ¤νΈ μ¶”μ¶
  - λ€λ…μ‚¬κ°€ μ—†λ” ν…μ¤νΈλ§ μ‚¬μ©
  - 2λ²μ§Έ λ…μ‚¬λ¥Ό `[MASK]`λ΅ λ§μ¤ν‚Ή
  - Top-1 μμΈ΅μ΄ μ •λ‹µ λ…μ‚¬μ™€ μΌμΉν•λ”μ§€ ν™•μΈ
- **μ μ λ²”μ„**: 0.0 ~ 1.0 (λ†’μ„μλ΅ μΆ‹μ)

### Real@5 (Entity Coreference Top-5 Recall)
- **λ©μ **: κ°μ²΄ μƒνΈμ°Έμ΅° ν•΄κ²°μ top-5 μ¬ν„μ¨ μΈ΅μ •
- **λ°©λ²•**: Real@1κ³Ό λ™μΌν•λ‚, top-5 μμΈ΅ μ¤‘μ— μ •λ‹µμ΄ μλ”μ§€ ν™•μΈ
- **μ μ λ²”μ„**: 0.0 ~ 1.0 (λ†’μ„μλ΅ μΆ‹μ)

### LAMBADA@1 (Language Modeling Accuracy)
- **λ©μ **: μΌλ°μ μΈ μ–Έμ–΄ λ¨λΈλ§ λ¥λ ¥ μΈ΅μ •
- **λ°©λ²•**: Ko-LAMBADA λ°μ΄ν„°μ…‹μ—μ„ λ§μ§€λ§‰ λ‹¨μ–΄ μμΈ΅
- **μ μ λ²”μ„**: 0.0 ~ 1.0 (λ†’μ„μλ΅ μΆ‹μ)

### μΆ…ν•© μ μ κ³„μ‚°
```
Score = 0.4 Γ— Real@1 + 0.3 Γ— Real@5 + 0.3 Γ— LAMBADA@1
```

## ν„μ¬ λ² μ¤νΈ μ„±λ¥ (λΉ„κµ κΈ°μ¤€)

**μ²΄ν¬ν¬μΈνΈ**: `runs/combined_experiment/checkpoint-1600` (Entity+MLM, seq_len=2048)
- **Real@1**: 67.78%
- **Real@5**: 82.44%
- **LAMBADA@1**: 66.13%
- **μΆ…ν•© μ μ**: 0.6785

## μ‚¬μ© λ°©λ²•

### 1. λ‹¨μΌ μ²΄ν¬ν¬μΈνΈ ν‰κ°€

```bash
# μλ™ μ‹ν€€μ¤ κΈΈμ΄ κ°μ§€
python scripts/evaluate_checkpoint.py \
    --checkpoint runs/mlm_v2_scratch_1536/checkpoint-655

# μ‹ν€€μ¤ κΈΈμ΄ λ…μ‹μ  μ§€μ •
python scripts/evaluate_checkpoint.py \
    --checkpoint runs/mlm_v2_scratch_1536/checkpoint-655 \
    --seq-len 1536

# κ²°κ³Ό μ €μ¥ λ””λ ‰ν† λ¦¬ μ§€μ •
python scripts/evaluate_checkpoint.py \
    --checkpoint runs/mlm_v2_scratch_1536/checkpoint-655 \
    --seq-len 1536 \
    --output-dir ./my_evaluation_results
```

### 2. λ°°μΉ ν‰κ°€ (λ¨λ“  μ²΄ν¬ν¬μΈνΈ)

#### λ°©λ²• A: μλ™ λ°°μΉ μ¤ν¬λ¦½νΈ μ‚¬μ©

```bash
# λ¨λ“  MLM v2 μ²΄ν¬ν¬μΈνΈ μλ™ ν‰κ°€
bash scripts/evaluate_all_mlm_v2_checkpoints.sh
```

μ΄ μ¤ν¬λ¦½νΈλ”:
- `runs/mlm_v2_scratch_1536/` μ λ¨λ“  μ²΄ν¬ν¬μΈνΈ ν‰κ°€ (seq_len=1536)
- `runs/mlm_v2_scratch_2048/` μ λ¨λ“  μ²΄ν¬ν¬μΈνΈ ν‰κ°€ (seq_len=2048)
- νƒ€μ„μ¤νƒ¬ν”„κ°€ ν¬ν•¨λ λ””λ ‰ν† λ¦¬μ— κ²°κ³Ό μ €μ¥
- μ§„ν–‰ μƒν™©κ³Ό ν†µκ³„ ν‘μ‹

#### λ°©λ²• B: μλ™ for λ£¨ν”„ μ‚¬μ©

**1536 μ²΄ν¬ν¬μΈνΈ:**
```bash
# λ¨λ“  1536 μ²΄ν¬ν¬μΈνΈ ν‰κ°€
for ckpt in runs/mlm_v2_scratch_1536/checkpoint-*; do
    echo "Evaluating $ckpt..."
    python scripts/evaluate_checkpoint.py --checkpoint "$ckpt" --seq-len 1536
done
```

**2048 μ²΄ν¬ν¬μΈνΈ:**
```bash
# λ¨λ“  2048 μ²΄ν¬ν¬μΈνΈ ν‰κ°€
for ckpt in runs/mlm_v2_scratch_2048/checkpoint-*; do
    echo "Evaluating $ckpt..."
    python scripts/evaluate_checkpoint.py --checkpoint "$ckpt" --seq-len 2048
done
```

**νΉμ • μ²΄ν¬ν¬μΈνΈ λ²”μ„λ§ ν‰κ°€:**
```bash
# checkpoint-300 μ΄μƒλ§ ν‰κ°€
for ckpt in runs/mlm_v2_scratch_1536/checkpoint-*; do
    checkpoint_num=$(basename "$ckpt" | sed 's/checkpoint-//')
    if [ "$checkpoint_num" -ge 300 ]; then
        python scripts/evaluate_checkpoint.py --checkpoint "$ckpt" --seq-len 1536
    fi
done
```

### 3. κ²°κ³Ό λ¶„μ„

#### JSON κ²°κ³Ό νμΌ λ³΄κΈ°
```bash
# μμκ² μ¶λ ¥
cat runs/mlm_v2_scratch_1536/checkpoint-655_eval_results.json | jq '.'

# μ£Όμ” λ©”νΈλ¦­λ§ μ¶”μ¶
cat runs/mlm_v2_scratch_1536/checkpoint-655_eval_results.json | jq '{checkpoint, real1, real5, lambada_top1}'
```

#### λ¨λ“  κ²°κ³Ό μ”μ•½
```bash
# λ¨λ“  κ²°κ³Ό νμΌμ—μ„ Real@1, Real@5 μ¶”μ¶
find runs/mlm_v2_scratch_* -name "*_eval_results.json" | while read file; do
    echo "=== $(basename $(dirname $file))/$(basename $file) ==="
    jq '{checkpoint, real1, real5, lambada_top1}' "$file"
    echo ""
done
```

#### μµκ³  μ„±λ¥ μ²΄ν¬ν¬μΈνΈ μ°ΎκΈ°
```bash
# Real@1 κΈ°μ¤€ μ •λ ¬
find runs/mlm_v2_scratch_* -name "*_eval_results.json" -exec jq -r '"\(.real1)\t\(.checkpoint)"' {} \; | sort -rn | head -10

# μΆ…ν•© μ μ κΈ°μ¤€ μ •λ ¬
find runs/mlm_v2_scratch_* -name "*_eval_results.json" -exec jq -r '"(0.4 * \(.real1) + 0.3 * \(.real5) + 0.3 * \(.lambada_top1))\t\(.checkpoint)"' {} \; | sort -rn | head -10
```

## ν„μ¬ μ‚¬μ© κ°€λ¥ν• μ²΄ν¬ν¬μΈνΈ

### MLM v2 @ 1536 (13κ°)
```
runs/mlm_v2_scratch_1536/checkpoint-65
runs/mlm_v2_scratch_1536/checkpoint-130
runs/mlm_v2_scratch_1536/checkpoint-195
runs/mlm_v2_scratch_1536/checkpoint-260
runs/mlm_v2_scratch_1536/checkpoint-325
runs/mlm_v2_scratch_1536/checkpoint-390
runs/mlm_v2_scratch_1536/checkpoint-455
runs/mlm_v2_scratch_1536/checkpoint-520
runs/mlm_v2_scratch_1536/checkpoint-585
runs/mlm_v2_scratch_1536/checkpoint-650
runs/mlm_v2_scratch_1536/checkpoint-655
```

### MLM v2 @ 2048 (8κ°)
```
runs/mlm_v2_scratch_2048/checkpoint-55
runs/mlm_v2_scratch_2048/checkpoint-110
runs/mlm_v2_scratch_2048/checkpoint-165
runs/mlm_v2_scratch_2048/checkpoint-220
runs/mlm_v2_scratch_2048/checkpoint-275
runs/mlm_v2_scratch_2048/checkpoint-330
runs/mlm_v2_scratch_2048/checkpoint-385
runs/mlm_v2_scratch_2048/checkpoint-440
```

## μμƒ μ‹¤ν–‰ μ‹κ°„

- **λ‹¨μΌ μ²΄ν¬ν¬μΈνΈ ν‰κ°€**: ~5-10λ¶„ (GPU μ‚¬μ© μ‹)
- **1536 μ „μ²΄ λ°°μΉ ν‰κ°€**: ~65-130λ¶„ (13κ° μ²΄ν¬ν¬μΈνΈ)
- **2048 μ „μ²΄ λ°°μΉ ν‰κ°€**: ~40-80λ¶„ (8κ° μ²΄ν¬ν¬μΈνΈ)

## μ¶λ ¥ μμ‹

```
================================================================================
β… ν‰κ°€ κ²°κ³Ό
================================================================================
μ²΄ν¬ν¬μΈνΈ: runs/mlm_v2_scratch_1536/checkpoint-655
μ‹ν€€μ¤ κΈΈμ΄: 1536
Coref μƒν”: 1600

LAMBADA@1: 0.6850 (68.50%)
Real@1:    0.6912 (69.12%)
Real@5:    0.8356 (83.56%)

ν‰κ°€ μ‹κ°„: 287.5μ΄

β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€
π“ μ„±λ¥ λΉ„κµ
β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€
μ΄μ „ λ² μ¤νΈ (checkpoint-1600, Entity+MLM, seq_len=2048):
  - Real@1: 67.78%
  - Real@5: 82.44%

ν„μ¬ μ²΄ν¬ν¬μΈνΈ (seq_len=1536):
  - Real@1: 69.12%
  - Real@5: 83.56%

λ³€ν™”:
  - Real@1: +1.34%p
  - Real@5: +1.12%p

μΆ…ν•© μ¤μ½”μ–΄ (0.4*Real@1 + 0.3*Real@5 + 0.3*LAMBADA@1):
  - μ΄μ „: 0.6785
  - ν„μ¬: 0.6824
  - λ³€ν™”: +0.39%p
================================================================================
```

## λ¬Έμ  ν•΄κ²°

### CUDA Out of Memory
```bash
# λ°°μΉ ν¬κΈ°λ¥Ό μ¤„μ΄λ ¤λ©΄ evaluate_checkpoint.pyμ batch_size=64λ¥Ό 32λ΅ λ³€κ²½
# λλ” CPUλ΅ μ‹¤ν–‰ (λλ¦Ό):
CUDA_VISIBLE_DEVICES=-1 python scripts/evaluate_checkpoint.py --checkpoint ...
```

### μ‹ν€€μ¤ κΈΈμ΄ κ°μ§€ μ‹¤ν¨
```bash
# --seq-lenμ„ λ…μ‹μ μΌλ΅ μ§€μ •
python scripts/evaluate_checkpoint.py --checkpoint ... --seq-len 1536
```

### safetensors λ¨λ“ μ—†μ
```bash
pip install safetensors
```

## λ‹¤μ λ‹¨κ³„

1. **μµκ³  μ„±λ¥ μ²΄ν¬ν¬μΈνΈ μ‹λ³„**: λ°°μΉ ν‰κ°€ ν›„ μµκ³  Real@1/Real@5 μ μ ν™•μΈ
2. **Entity v2 fine-tuning**: μµκ³  μ„±λ¥ μ²΄ν¬ν¬μΈνΈλ¥Ό κΈ°λ°μΌλ΅ Entity v2 λ°μ΄ν„°μ…‹μΌλ΅ μ¶”κ°€ ν•™μµ
3. **μ„±λ¥ λΉ„κµ**: MLM v2 λ‹¨λ… vs Entity v2 fine-tuning κ²°κ³Ό λΉ„κµ

### Entity v2 Fine-tuning λ…λ Ήμ–΄
```bash
# μµκ³  μ„±λ¥ MLM v2 μ²΄ν¬ν¬μΈνΈλ΅ Entity ν•™μµ
python scripts/run_entity_coref_finetune_v2.py \
    --checkpoint runs/mlm_v2_scratch_1536/checkpoint-655 \
    --dataset prepared_datasets/entity_coref_v2_1536 \
    --epochs 5 \
    --output-dir runs/entity_v2_finetune_from_mlm_v2
```

## κ΄€λ ¨ νμΌ

- `scripts/evaluate_checkpoint.py` - λ‹¨μΌ μ²΄ν¬ν¬μΈνΈ ν‰κ°€ μ¤ν¬λ¦½νΈ
- `scripts/evaluate_all_mlm_v2_checkpoints.sh` - λ°°μΉ ν‰κ°€ μλ™ν™” μ¤ν¬λ¦½νΈ
- `scripts/run_entity_coref_finetune_v2.py` - Entity v2 fine-tuning μ¤ν¬λ¦½νΈ
- `coref_automl/tune.py` - ν‰κ°€ ν•¨μ κµ¬ν„ (`eval_real_coref_top1`, `eval_real_coref_top5`)
